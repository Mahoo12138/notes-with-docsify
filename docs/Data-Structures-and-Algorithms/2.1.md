### 对比程序，还是算法？

**如何对比两个程序？**

比较程序的“好坏” ，有更多因素如代码风格、可读性等等。我们主要感兴趣的是算法本身特性，算法分析主要就是从计算资源消耗的角度来评判和比较算法，更高效利用计算资源，或者更少占用计算资源的算法，就是好算法。 

**程序和算法的区别？**

+ 算法是对问题解决的分步描述；
+ 程序则是采用某种编程语言实现的算法，同一个 算法通过不同的程序员采用不同的编程语言，能 产生很多程序

### 计算资源指标

那么何为计算资源？

+ 一种是算法解决问题过程中需要的**存储空间或内存**，但存储空间受到问题自身数据规模的变化影响 要区分哪些存储空间是问题本身描述所需，哪些 是算法占用，不容易

+ 另一种是算法的**执行时间**，我们可以对程序进行实际运行测试，获得真实的运行时间。

  > **运行时间检测**：Python中有一个time模块，可以获取计算机系统当前时间，start = time.time() 

累计求和程序的运行时间检测，在我电脑上，计算到 10000 大约需要 0.0010085 秒，每翻十倍，时间也是大致接近 10 倍的关系：

```python
import time

def sumOfn(n):
    start = time.time()
    sum = 0
    for i in range(1,n + 1):
        sum = sum + i
    end = time.time()
    return sum, end - start

print("Sum is %d required %10.7f secends"% sumOfn(10000))
print("Sum is %d required %10.7f secends"% sumOfn(100000))
print("Sum is %d required %10.7f secends"% sumOfn(1000000))
```

在第一种算法中，包含了一个循环，可能会执行更多语句，这个循环运行次数跟累加值 n 有关系，n增加，循环次数也增加。当我们使用第二种无迭代的累计算法，需要注意的是，这种算法的运行时间比前种都短很多，运行时间与累计对象 n 的大小没有关系（前种算法是倍数增长关系）：

```python
def sumOfn2(n):
    start = time.time()
    sum = n * (n + 1) 
    end = time.time()
    return sum, end - start

print("Sum is %d required %10.7f secends"% sumOfn(10000))
print("Sum is %d required %10.7f secends"% sumOfn2(10000))
print("Sum is %d required %10.7f secends"% sumOfn2(100000))
print("Sum is %d required %10.7f secends"% sumOfn2(1000000))
```

### 运行时间检测的分析

关于运行时间的实际检测，有点问题，主要考虑到编程语言和运行环境；

同一个算法，采用**不同的编程语言**编写， 放在**不同的机器**上运行，得到的运行时间会不一样，有时候会大不一样： 比如把非迭代算法放在老旧机器上跑，甚至可能慢过新机器上的迭代算法。

我们需要更好的方法来衡量算法运行时间，这个指标与具体的机器、程序、运行时段都无关。

